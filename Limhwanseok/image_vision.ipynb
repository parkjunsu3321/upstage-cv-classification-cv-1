{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c726893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f944e479",
   "metadata": {},
   "source": [
    "### í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b4b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 1) Standard Library =====\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# ===== 2) Third-Party Core =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ===== 3) PyTorch Core =====\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR  # (1) ì—¬ê¸°ì„œ í•œ ë²ˆ ì„í¬íŠ¸\n",
    "\n",
    "# ===== 4) TorchVision / Data Loading =====\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# ===== 5) Albumentations =====\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations.pytorch as A_torch  # A_torch.ToTensorV2()ë„ ì‚¬ìš© ê°€ëŠ¥\n",
    "\n",
    "# ===== 6) Models (timm) =====\n",
    "import timm\n",
    "\n",
    "# ===== 7) Metrics / CV (scikit-learn) =====\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ===== 8) Vision / Utility =====\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===== 9) Visualization =====\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# TTAë¥¼ ìœ„í•œ ë³´ì¡° í•¨ìˆ˜\n",
    "def _orientation_views(batch_t: torch.Tensor):\n",
    "    # batch_t: [B, C, H, W]\n",
    "    outs = []\n",
    "    # 0) original\n",
    "    outs.append(batch_t)\n",
    "    # 1) horizontal flip\n",
    "    outs.append(torch.flip(batch_t, dims=[3]))\n",
    "    # 2) 180Â°\n",
    "    outs.append(torch.rot90(batch_t, k=2, dims=[2, 3]))\n",
    "    # 3) 180Â° + hflip\n",
    "    o = torch.rot90(batch_t, k=2, dims=[2, 3])\n",
    "    outs.append(torch.flip(o, dims=[3]))\n",
    "    return outs\n",
    "\n",
    "# TTA ì˜ˆì¸¡ í‰ê·  í•¨ìˆ˜\n",
    "def tta_mean_logits(model, batch_t: torch.Tensor, device, use_cuda: bool):\n",
    "    logits_list = []\n",
    "    for view in _orientation_views(batch_t):\n",
    "        with torch.amp.autocast(device_type='cuda', enabled=use_cuda):\n",
    "            logits = model(view)\n",
    "        logits_list.append(logits)\n",
    "    # [4, B, C] -> [B, C]\n",
    "    return torch.stack(logits_list, dim=0).mean(dim=0)\n",
    "\n",
    "# ì‹œë“œ ê³ ì •\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True  \n",
    "    torch.backends.cudnn.benchmark = False     \n",
    "set_seed(42)\n",
    "\n",
    "\n",
    "# device/AMP ì„¤ì •\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6468660",
   "metadata": {},
   "source": [
    "### ê¸°ì¡´ ë°ì´í„° ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a0362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- K-Fold ì„¤ì • ---\n",
    "N_SPLITS = 5 \n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "df = pd.read_csv(\"/root/cv_project/datasets/data/train.csv\")\n",
    "\n",
    "print(f\"âœ… K-Fold: Using {N_SPLITS} splits on {len(df)} total images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f64b2cc",
   "metadata": {},
   "source": [
    "### ê°€ì¤‘ì¹˜ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e1a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- í´ë˜ìŠ¤ë³„ ê°œìˆ˜ ê³„ì‚° ---\n",
    "class_counts = Counter(df[\"target\"].tolist())\n",
    "num_classes = df[\"target\"].nunique()\n",
    "total_samples = len(df)\n",
    "\n",
    "# --- í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜ ê³„ì‚° (ì •ê·œí™”ëœ ì—­ë¹ˆë„ ë°©ì‹) ---\n",
    "freq = np.array([class_counts[i] for i in range(num_classes)], dtype=np.float32)\n",
    "inv_freq = 1.0 / np.maximum(freq, 1.0)  # 0 ë‚˜ëˆ—ì…ˆ ë°©ì§€\n",
    "weights = inv_freq * (num_classes / inv_freq.sum())  # í•© = í´ë˜ìŠ¤ ìˆ˜ë¡œ ì •ê·œí™”\n",
    "\n",
    "# --- í…ì„œë¡œ ë³€í™˜ í›„ GPUë¡œ ì´ë™ ---\n",
    "class_weights = torch.tensor(weights, dtype=torch.float, device=device)\n",
    "print(f\"âœ… Class weights for WeightedLoss calculated: {np.round(weights, 4)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9186c868",
   "metadata": {},
   "source": [
    "### í´ë˜ìŠ¤ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af74c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ë¥¼ ì •ì˜\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, path, transform=None): \n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        \n",
    "        print(\"Checking data integrity...\")\n",
    "        name_col = df.columns[0]     # ID\n",
    "        target_col = df.columns[1]   # target\n",
    "        \n",
    "        clean_data = []\n",
    "        # ì¡´ì¬í•˜ëŠ” ì´ë¯¸ì§€ë§Œ í•„í„°ë§\n",
    "        for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Cleaning CSV\"):\n",
    "            file_path = os.path.join(self.path, row[name_col])\n",
    "            if os.path.exists(file_path):\n",
    "                clean_data.append((row[name_col], row[target_col]))\n",
    "        \n",
    "        self.df = clean_data \n",
    "        print(f\"Original: {len(df)}, Found: {len(self.df)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx] \n",
    "        \n",
    "        # ì´ë¯¸ì§€ë¥¼ RGBë¡œ ê°•ì œ ë³€í™˜(í‘ë°±ì´ë¯¸ì§€ ëŒ€ë¹„)\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)).convert('RGB')) \n",
    "        \n",
    "        # Augmentaions ë³€í™˜ ì ìš©\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        \n",
    "        # ğŸ‘ˆ targetì„ intê°€ ì•„ë‹Œ long tensorë¡œ ì§ì ‘ ë³€í™˜ (ê°€ì¥ ì¤‘ìš”)\n",
    "        # loss_fn(preds, targets)ëŠ” targetsê°€ LongTensorì´ê¸°ë¥¼ ê¸°ëŒ€í•©ë‹ˆë‹¤.\n",
    "        return img, torch.tensor(target, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d794c736",
   "metadata": {},
   "source": [
    "### epoch ê³„ì‚° í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9309b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµìš© í•¨ìˆ˜ (AMP ì•ˆì •í™” ì ìš©)\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device, scaler):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    preds_list, targets_list = [], []\n",
    "\n",
    "    pbar = tqdm(loader, leave=False)\n",
    "    for image, targets in pbar:\n",
    "        \n",
    "        # GPUì „ì†¡ ìµœì í™”\n",
    "        image = image.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "\n",
    "        # AMP: CUDAì¼ ë•Œë§Œ í™œì„±í™”\n",
    "        with torch.amp.autocast(device_type='cuda', enabled=use_cuda):\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "        \n",
    "        # Gradient ê³„ì‚° ë° íŒŒë¼ë¯¸í„° ê°±ì‹ \n",
    "        if use_cuda:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # í†µê³„ê°’ ê¸°ë¡\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "    return {\"train_loss\": train_loss, \"train_acc\": train_acc, \"train_f1\": train_f1}\n",
    "\n",
    "\n",
    "# ê²€ì¦ìš© í•¨ìˆ˜ (AMP ì•ˆì •í™” ì ìš©)\n",
    "@torch.no_grad()   # Gradient ê³„ì‚° ë¹„í™œì„±í™”\n",
    "def validate_one_epoch(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    preds_list, targets_list = [], []\n",
    "\n",
    "    for image, targets in loader:\n",
    "        image = image.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "        # AMP: CUDAì¼ ë•Œë§Œ í™œì„±í™”\n",
    "        with torch.amp.autocast(device_type='cuda', enabled=use_cuda):\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "    return {\"val_loss\": val_loss, \"val_acc\": val_acc, \"val_f1\": val_f1}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51fdc37",
   "metadata": {},
   "source": [
    "### ëª¨ë¸/í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„ íƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bd9026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data config\n",
    "data_path = '/root/cv_project/datasets/data'\n",
    "\n",
    "# model config\n",
    "model_name = 'swin_base_patch4_window12_384' \n",
    "\n",
    "# training config\n",
    "img_size = 384  # ìˆ˜ì •ëœ ë¶€ë¶„\n",
    "LR = 5e-5\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 8\n",
    "num_workers = 4\n",
    "PATIENCE = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bc3618",
   "metadata": {},
   "source": [
    "### ì´ë¯¸ì§€ ì¡°ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638fc254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµìš© ì´ë¯¸ì§€ ë³€í™˜\n",
    "trn_transform = A.Compose([\n",
    "    A.LongestMaxSize(max_size=img_size), # 384ì— ë§ì¶¤\n",
    "    A.PadIfNeeded(\n",
    "        min_height=img_size, \n",
    "        min_width=img_size, \n",
    "        border_mode=0,   # 0 = cv2.BORDER_CONSTANT (ê³ ì •ìƒ‰)\n",
    "        value=255        # íŒ¨ë”©ìƒ‰ìƒ (í°ìƒ‰)\n",
    "    ), \n",
    "    # ------------------------------------------------\n",
    "    \n",
    "    # ê¸°í•˜ ë³€í™˜: ê³¼í•˜ì§€ ì•Šê²Œ, ë“œë¬¼ê²Œ ê°•í•œ ë°©í–¥ë§Œ ì„ê¸°\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.02,  # ìœ„ì¹˜ ì´ë™ 2%\n",
    "        scale_limit=0.05,  # í¬ê¸° 5%\n",
    "        rotate_limit=5,    # íšŒì „ 5ë„\n",
    "        p=0.5              # í™•ë¥  50%\n",
    "    ),\n",
    "    A.Perspective(scale=(0.02, 0.07), p=0.25),   # ì•½í•œ ì›ê·¼ ì™œê³¡\n",
    "    A.RandomRotate90(p=0.10),                    # 90/180/270 ì¤‘ í•˜ë‚˜(10% í™•ë¥ )\n",
    "    \n",
    "    # ì¢Œìš°/ìƒí•˜ ë°˜ì „\n",
    "    A.HorizontalFlip(p=0.25),\n",
    "    A.VerticalFlip(p=0.08),\n",
    "    \n",
    "    # ì„ ëª…ë„/ëŒ€ë¹„\n",
    "    A.OneOf([\n",
    "        A.Sharpen(alpha=(0.1, 0.3), lightness=(0.9, 1.1), p=1.0),   # ë¬¸ì„œ ê°€ì¥ìë¦¬\n",
    "        A.CLAHE(clip_limit=(2, 4), tile_grid_size=(8, 8), p=1.0),   # ë°ê¸° ë³´ì •\n",
    "    ], p=0.45),\n",
    "\n",
    "    # ë°ê¸°/ëŒ€ë¹„ ë³€í™” -> ìŠ¤ìºë„ˆ ë…¸ì´ì¦ˆ, ê·¸ë¦¼ì ì°¨ì´\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.12, contrast_limit=0.12, p=0.4),\n",
    "    A.ToGray(p=0.25),\n",
    "\n",
    "    # ì •ê·œí™” + í…ì„œ ë³€í™˜\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    A_torch.ToTensorV2(),\n",
    "])\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ ë³€í™˜ \n",
    "tst_transform = A.Compose([\n",
    "    A.LongestMaxSize(max_size=img_size), \n",
    "    A.PadIfNeeded(\n",
    "        min_height=img_size, \n",
    "        min_width=img_size, \n",
    "        border_mode=0, \n",
    "        value=255\n",
    "    ),\n",
    "    # í…ŒìŠ¤íŠ¸ìš©ì€ Augmentation ì œê±°\n",
    "    \n",
    "    # ì •ê·œí™” + í…ì„œ ë³€í™˜\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    A_torch.ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52536117",
   "metadata": {},
   "source": [
    "### dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c669f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¶”ë¡ ìš© í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ êµ¬ì„±\n",
    "tst_df = pd.read_csv(\"/root/cv_project/datasets/data/sample_submission.csv\")\n",
    "tst_dataset = ImageDataset(\n",
    "    tst_df, \n",
    "    \"/root/cv_project/datasets/data/test/\",\n",
    "    transform=tst_transform\n",
    ")\n",
    "tst_loader = DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6323c6",
   "metadata": {},
   "source": [
    "### k-fold í•™ìŠµ ë£¨í”„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c998911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- K-Fold í•™ìŠµ ë£¨í”„ ì‹œì‘ ---\n",
    "\n",
    "all_fold_val_f1 = [] # ëª¨ë“  Foldì˜ ê²€ì¦ F1 ìŠ¤ì½”ì–´ë¥¼ ì €ì¥\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(skf.split(df, df['target'])):\n",
    "    print(f\"\\n--- FOLD {fold + 1}/{N_SPLITS} START ---\")\n",
    "\n",
    "    # 1. Foldë³„ë¡œ ë°ì´í„° ë¶„ë¦¬\n",
    "    trn_df = df.iloc[trn_idx]\n",
    "    val_df = df.iloc[val_idx]\n",
    "\n",
    "    # 2. Foldë³„ë¡œ Dataset ë° DataLoader ìƒì„±\n",
    "    trn_dataset = ImageDataset(trn_df, \"/root/cv_project/datasets/data/train/\", transform=trn_transform)\n",
    "    val_dataset = ImageDataset(val_df, \"/root/cv_project/datasets/data/train/\", transform=tst_transform)\n",
    "\n",
    "    trn_loader = DataLoader(\n",
    "        trn_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # 3. ë§¤ Foldë§ˆë‹¤ ëª¨ë¸, ì˜µí‹°ë§ˆì´ì €, ìŠ¤ì¼€ì¤„ëŸ¬ ìƒˆë¡œ ì´ˆê¸°í™”\n",
    "    model = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=True,\n",
    "        num_classes=17\n",
    "    ).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=class_weights,label_smoothing=0.1)\n",
    "    optimizer = AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "    \n",
    "    \n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "\n",
    "    best_f1 = -1\n",
    "    best_epoch = 0\n",
    "    epochs_no_improve = 0  \n",
    "\n",
    "    # 4. Epoch í•™ìŠµ ë£¨í”„\n",
    "    for epoch in range(EPOCHS):\n",
    "        tr = train_one_epoch(trn_loader, model, optimizer, loss_fn, device=device, scaler=scaler)\n",
    "        va = validate_one_epoch(val_loader, model, loss_fn, device=device)\n",
    "\n",
    "        print(f\"[Fold {fold+1}/Epoch {epoch}] Train F1: {tr['train_f1']:.4f} | Val F1: {va['val_f1']:.4f}\")\n",
    "\n",
    "        # ë² ìŠ¤íŠ¸ ëª¨ë¸ ê°±ì‹  (f1ê¸°ì¤€)\n",
    "        if va[\"val_f1\"] > best_f1:\n",
    "            best_f1 = va[\"val_f1\"]\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), f\"output/best_model_fold{fold}.pt\") \n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # ì¡°ê¸° ì¢…ë£Œ\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(f\"--- Early Stopping at Epoch {epoch} as Val_F1 did not improve for {PATIENCE} epochs ---\")\n",
    "            break\n",
    "\n",
    "    print(f\"âœ… Fold {fold+1} Best Val_F1: {best_f1:.4f} (epoch {best_epoch})\")\n",
    "    all_fold_val_f1.append(best_f1)\n",
    "\n",
    "print(f\"\\n--- K-Fold Training Finished ---\")\n",
    "print(f\"âœ… All Fold Best F1 Scores: {all_fold_val_f1}\")\n",
    "mean_f1 = np.mean(all_fold_val_f1)\n",
    "std_f1 = np.std(all_fold_val_f1)\n",
    "\n",
    "# í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ì¶œë ¥\n",
    "print(f\"âœ… Final CV Score (Mean Â± Std): {mean_f1:.4f} Â± {std_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001b263e",
   "metadata": {},
   "source": [
    "### oof ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b855cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ OOF(Out-Of-Fold) ì˜ˆì¸¡ ìƒì„± â”€â”€\n",
    "print(f\"\\n--- Generating Out-of-Fold (OOF) Predictions ---\")\n",
    "\n",
    "df['oof_preds'] = -1\n",
    "meta_df = pd.read_csv(\"/root/cv_project/datasets/data/meta.csv\")\n",
    "class_name_map = dict(zip(meta_df['target'], meta_df['class_name']))\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(skf.split(df, df['target'])):\n",
    "    print(f\"Generating OOF for Fold {fold + 1}/{N_SPLITS}\")\n",
    "\n",
    "    val_df = df.iloc[val_idx]\n",
    "    val_dataset = ImageDataset(\n",
    "        val_df,\n",
    "        \"/root/cv_project/datasets/data/train/\",\n",
    "        transform=tst_transform\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    best_model_path = f\"output/best_model_fold{fold}.pt\"\n",
    "    if os.path.exists(best_model_path):\n",
    "        model = timm.create_model(model_name, pretrained=False, num_classes=17).to(device)\n",
    "        model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        fold_preds = []\n",
    "        with torch.inference_mode():\n",
    "            for image, _ in tqdm(val_loader, desc=f\"Generating OOF Fold {fold + 1}\"):\n",
    "                image = image.to(device, non_blocking=True)\n",
    "                # â˜… TTA ì œê±°: ê·¸ëŒ€ë¡œ forward í›„ argmax\n",
    "                logits = model(image)\n",
    "                pred = logits.argmax(dim=1).detach().cpu().numpy()\n",
    "                fold_preds.extend(pred)\n",
    "\n",
    "        assert len(fold_preds) == len(val_df), \"OOF length mismatch\"\n",
    "        df.loc[val_df.index, 'oof_preds'] = fold_preds\n",
    "    else:\n",
    "        print(f\"âš ï¸ Model for Fold {fold} not found!\")\n",
    "\n",
    "df['oof_preds'] = df['oof_preds'].astype(int)\n",
    "print(\"âœ… OOF Prediction generation finished.\")\n",
    "\n",
    "\n",
    "df['oof_preds'] = df['oof_preds'].astype(int)\n",
    "\n",
    "# ë¶„ì„ìš© DF\n",
    "analyzable_df = df[df['oof_preds'] != -1].copy()\n",
    "analyzable_df['target_name'] = analyzable_df['target'].map(class_name_map)\n",
    "analyzable_df['oof_preds_name'] = analyzable_df['oof_preds'].map(class_name_map)\n",
    "\n",
    "print(\"\\n--- Top 10 Misclassified Classes (Based on True Label) ---\")\n",
    "print(\n",
    "    analyzable_df[analyzable_df['target'] != analyzable_df['oof_preds']]\n",
    "    ['target_name'].value_counts().head(10)\n",
    ")\n",
    "\n",
    "print(\"\\n--- Generating Confusion Matrix ---\")\n",
    "ordered_targets = sorted(meta_df['target'].unique().tolist())\n",
    "class_labels = [class_name_map[i] for i in ordered_targets]\n",
    "\n",
    "cm = confusion_matrix(\n",
    "    analyzable_df['target'],\n",
    "    analyzable_df['oof_preds'],\n",
    "    labels=ordered_targets\n",
    ")\n",
    "cm_sum = np.nansum(cm, axis=1)[:, np.newaxis]\n",
    "cm_normalized = np.divide(\n",
    "    cm.astype('float'), cm_sum,\n",
    "    out=np.zeros_like(cm, dtype=float),\n",
    "    where=(cm_sum != 0)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(18, 14))\n",
    "sns.heatmap(\n",
    "    cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
    "    xticklabels=class_labels, yticklabels=class_labels\n",
    ")\n",
    "plt.title(\"OOF Confusion Matrix (Normalized by True Label)\", fontsize=16)\n",
    "plt.ylabel(\"True Label (ì‹¤ì œ ì •ë‹µ)\", fontsize=12)\n",
    "plt.xlabel(\"Predicted Label (ëª¨ë¸ ì˜ˆì¸¡)\", fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f192017",
   "metadata": {},
   "source": [
    "### k-fold ì•™ìƒë¸”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3b5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ K-Fold ì•™ìƒë¸” ì¶”ë¡  â”€â”€\n",
    "print(f\"\\n--- Starting K-Fold Ensemble Inference ---\")\n",
    "\n",
    "all_fold_logits = []  # ê° foldì˜ ì „ì²´ í…ŒìŠ¤íŠ¸ ë¡œì§“ [N, C]\n",
    "\n",
    "for fold in range(N_SPLITS):\n",
    "    best_model_path = f\"output/best_model_fold{fold}.pt\"\n",
    "    if os.path.exists(best_model_path):\n",
    "        print(f\"âœ… Loading model from Fold {fold}: {best_model_path}\")\n",
    "        model = timm.create_model(model_name, pretrained=False, num_classes=17).to(device)\n",
    "        model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        fold_logits = []\n",
    "        with torch.inference_mode():\n",
    "            for image, _ in tqdm(tst_loader, desc=f\"Predicting Fold {fold} (no TTA)\"):\n",
    "                image = image.to(device, non_blocking=True)\n",
    "                with torch.amp.autocast(device_type='cuda', enabled=torch.cuda.is_available()):\n",
    "                    logits = model(image)  # [B, C]\n",
    "                fold_logits.append(logits.detach().cpu().numpy())\n",
    "\n",
    "        fold_logits = np.concatenate(fold_logits, axis=0)  # [N, C]\n",
    "        all_fold_logits.append(fold_logits)\n",
    "    else:\n",
    "        print(f\"âš ï¸ Model for Fold {fold} not found!\")\n",
    "\n",
    "# Fold í‰ê·  (logit í‰ê· ) â†’ í™•ë¥  â†’ ì˜ˆì¸¡\n",
    "avg_logits = np.mean(all_fold_logits, axis=0)                 # [N, C]\n",
    "# torch ì—†ì´ numpy softmax\n",
    "exp = np.exp(avg_logits - np.max(avg_logits, axis=1, keepdims=True))\n",
    "avg_probs = exp / np.sum(exp, axis=1, keepdims=True)          # [N, C]\n",
    "\n",
    "# ì €ì¥ íŒŒì¼\n",
    "np.save(\"output/swin_logits.npy\", avg_logits)\n",
    "np.save(\"output/swin_probs.npy\",  avg_probs)\n",
    "\n",
    "final_preds = np.argmax(avg_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1a2c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ì œì¶œ íŒŒì¼ ìƒì„± ---\n",
    "pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = final_preds # ìµœì¢… ì•™ìƒë¸” ì˜ˆì¸¡ ê²°ê³¼\n",
    "\n",
    "sample_submission_df = pd.read_csv(\"/root/cv_project/datasets/data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()\n",
    "\n",
    "pred_df.to_csv(\"output/pred_14.csv\", index=False) # ìƒˆ ì´ë¦„ìœ¼ë¡œ ì €ì¥\n",
    "print(\"\\nâœ… K-Fold ensemble prediction saved to 'output/pred_kfold.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373c0f17",
   "metadata": {},
   "source": [
    "### vit ëª¨ë¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bedd44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
