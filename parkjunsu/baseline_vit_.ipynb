{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1762168839632,
     "user": {
      "displayName": "박준수",
      "userId": "08541241824626674630"
     },
     "user_tz": -540
    },
    "id": "H9xRQBagRVCn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/trafic/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn, optim\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1762168839682,
     "user": {
      "displayName": "박준수",
      "userId": "08541241824626674630"
     },
     "user_tz": -540
    },
    "id": "QuHpRpZpRbe4"
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 1️⃣ Transform 정의\n",
    "# ---------------------------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2️⃣ CSV 기반 커스텀 Dataset 정의\n",
    "# ---------------------------------------------------\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None, label_encoder=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.label_encoder = label_encoder\n",
    "\n",
    "        # 레이블이 존재하면 숫자로 변환\n",
    "        if 'target' in self.data.columns and self.label_encoder is not None:\n",
    "            self.data['target'] = self.label_encoder.transform(self.data['target'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = f\"{self.img_dir}/{self.data.iloc[idx, 0]}\"\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # 레이블이 없으면 -1 반환\n",
    "        if 'target' in self.data.columns:\n",
    "            label = torch.tensor(self.data.iloc[idx, 1], dtype=torch.long)\n",
    "            return image, label\n",
    "        else:\n",
    "            return image, -1\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3️⃣ LabelEncoder 준비 (문자열 레이블 → 숫자)\n",
    "# ---------------------------------------------------\n",
    "train_df = pd.read_csv(\"/root/CV_/datasets/data/train.csv\")\n",
    "le = LabelEncoder()\n",
    "train_df['target'] = le.fit_transform(train_df['target'])\n",
    "\n",
    "# Dataset 생성\n",
    "train_dataset = CustomImageDataset(\n",
    "    csv_file=\"/root/CV_/datasets/data/train.csv\",\n",
    "    img_dir=\"/root/CV_/datasets/data/train\",\n",
    "    transform=transform,\n",
    "    label_encoder=le\n",
    ")\n",
    "\n",
    "test_dataset = CustomImageDataset(\n",
    "    csv_file=\"/root/CV_/datasets/data/sample_submission.csv\",\n",
    "    img_dir=\"/root/CV_/datasets/data/test\",\n",
    "    transform=transform,\n",
    "    label_encoder=le  # test에는 레이블 없어도 무방\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 655,
     "status": "ok",
     "timestamp": 1762168840342,
     "user": {
      "displayName": "박준수",
      "userId": "08541241824626674630"
     },
     "user_tz": -540
    },
    "id": "Y5D0SmhMSYZD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 4️⃣ 모델 준비\n",
    "# ---------------------------------------------------\n",
    "processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"google/vit-base-patch16-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1762168840367,
     "user": {
      "displayName": "박준수",
      "userId": "08541241824626674630"
     },
     "user_tz": -540
    },
    "id": "qaCgfG3bSZio"
   },
   "outputs": [],
   "source": [
    "# 출력 클래스 수를 train dataset에 맞춤\n",
    "num_classes = len(le.classes_)\n",
    "if model.config.num_labels != num_classes:\n",
    "    # 마지막 classifier 레이어 이름 확인\n",
    "    if hasattr(model, 'classifier'):\n",
    "        in_features = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(in_features, num_classes)\n",
    "    elif hasattr(model, 'score'):\n",
    "        in_features = model.score.in_features\n",
    "        model.score = nn.Linear(in_features, num_classes)\n",
    "    else:\n",
    "        print(\"모델 구조 확인 필요 - 마지막 레이어 이름 다를 수 있음\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hmbGDftjSgN1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Loss: 0.8920\n",
      "Epoch 2/30 - Loss: 0.2196\n",
      "Epoch 3/30 - Loss: 0.1274\n",
      "Epoch 4/30 - Loss: 0.0753\n",
      "Epoch 5/30 - Loss: 0.0602\n",
      "Epoch 6/30 - Loss: 0.0550\n",
      "Epoch 7/30 - Loss: 0.0153\n",
      "Epoch 8/30 - Loss: 0.0357\n",
      "Epoch 9/30 - Loss: 0.0074\n",
      "Epoch 10/30 - Loss: 0.0029\n",
      "Epoch 11/30 - Loss: 0.0014\n",
      "Epoch 12/30 - Loss: 0.0012\n",
      "Epoch 13/30 - Loss: 0.0010\n",
      "Epoch 14/30 - Loss: 0.0009\n",
      "Epoch 15/30 - Loss: 0.0008\n",
      "Epoch 16/30 - Loss: 0.0007\n",
      "Epoch 17/30 - Loss: 0.0006\n",
      "Epoch 18/30 - Loss: 0.0005\n",
      "Epoch 19/30 - Loss: 0.0005\n",
      "Epoch 20/30 - Loss: 0.0004\n",
      "Epoch 21/30 - Loss: 0.0004\n",
      "Epoch 22/30 - Loss: 0.0004\n",
      "Epoch 23/30 - Loss: 0.0003\n",
      "Epoch 24/30 - Loss: 0.0003\n",
      "Epoch 25/30 - Loss: 0.0003\n",
      "Epoch 26/30 - Loss: 0.0002\n",
      "Epoch 27/30 - Loss: 0.0002\n",
      "Epoch 28/30 - Loss: 0.0002\n",
      "Epoch 29/30 - Loss: 0.0002\n",
      "Epoch 30/30 - Loss: 0.0002\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 5️⃣ 학습 Loop\n",
    "# ---------------------------------------------------\n",
    "num_epochs = 30             \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "V-K7bos1Shh5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0: Predicted class = 2\n",
      "Image 1: Predicted class = 6\n",
      "Image 2: Predicted class = 5\n",
      "Image 3: Predicted class = 13\n",
      "Image 4: Predicted class = 2\n",
      "Image 5: Predicted class = 15\n",
      "Image 6: Predicted class = 0\n",
      "Image 7: Predicted class = 8\n",
      "Image 8: Predicted class = 15\n",
      "Image 9: Predicted class = 11\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 6️⃣ 테스트 예측\n",
    "# ---------------------------------------------------\n",
    "model.eval()\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, _ in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images).logits\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "# 숫자를 클래스 이름으로 변환\n",
    "pred_labels = le.inverse_transform(all_preds)\n",
    "\n",
    "# 결과 확인\n",
    "for i, label in enumerate(pred_labels[:10]):\n",
    "    print(f\"Image {i}: Predicted class = {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('/root/CV_/datasets/data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['target'] = pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('vit_output_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO+Baxyz9EVb7XKhin+l53F",
   "mount_file_id": "1GpeCB3McjTtqGCKmoSA9DzENQ4UQNOe_",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "trafic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
